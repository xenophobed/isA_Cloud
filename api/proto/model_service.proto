// model_service.proto - 模型服务gRPC接口
syntax = "proto3";

package isa.model;

option go_package = "github.com/isa-cloud/isa_cloud/pkg/proto/model";

import "common.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/struct.proto";

// ========================================
// 模型服务
// ========================================

service ModelService {
    // 模型管理
    rpc ListModels(ListModelsRequest) returns (ListModelsResponse);
    rpc GetModel(GetModelRequest) returns (GetModelResponse);
    rpc DeployModel(DeployModelRequest) returns (DeployModelResponse);
    rpc UndeployModel(UndeployModelRequest) returns (UndeployModelResponse);
    rpc GetModelStatus(GetModelStatusRequest) returns (GetModelStatusResponse);
    
    // 推理服务
    rpc GenerateText(GenerateTextRequest) returns (GenerateTextResponse);
    rpc ChatCompletion(ChatCompletionRequest) returns (ChatCompletionResponse);
    rpc GenerateEmbedding(GenerateEmbeddingRequest) returns (GenerateEmbeddingResponse);
    
    // 批量推理
    rpc BatchInference(BatchInferenceRequest) returns (BatchInferenceResponse);
    rpc GetBatchStatus(GetBatchStatusRequest) returns (GetBatchStatusResponse);
    
    // 模型健康状态
    rpc GetModelHealth(GetModelHealthRequest) returns (GetModelHealthResponse);
    rpc GetServiceHealth(GetServiceHealthRequest) returns (GetServiceHealthResponse);
}

// ========================================
// 模型数据结构
// ========================================

message Model {
    string model_id = 1;
    string name = 2;
    string version = 3;
    ModelType type = 4;
    ModelStatus status = 5;
    string organization_id = 6;
    ModelConfig config = 7;
    ModelMetrics metrics = 8;
    google.protobuf.Timestamp deployed_at = 9;
    string deployment_backend = 10; // transformers, vllm, tensorrt
}

enum ModelType {
    MODEL_TYPE_UNKNOWN = 0;
    MODEL_TYPE_LLM = 1;
    MODEL_TYPE_VISION = 2;
    MODEL_TYPE_AUDIO = 3;
    MODEL_TYPE_EMBEDDING = 4;
    MODEL_TYPE_MULTIMODAL = 5;
}

enum ModelStatus {
    MODEL_STATUS_UNKNOWN = 0;
    MODEL_STATUS_LOADING = 1;
    MODEL_STATUS_READY = 2;
    MODEL_STATUS_BUSY = 3;
    MODEL_STATUS_ERROR = 4;
    MODEL_STATUS_UNLOADING = 5;
}

message ModelConfig {
    string framework = 1;      // transformers, vllm, tensorrt
    string precision = 2;      // float16, int8, int4
    int32 max_batch_size = 3;
    int32 max_sequence_length = 4;
    int32 gpu_count = 5;
    google.protobuf.Struct parameters = 6;
}

message ModelMetrics {
    int64 total_requests = 1;
    int64 successful_requests = 2;
    int64 failed_requests = 3;
    double average_latency_ms = 4;
    double tokens_per_second = 5;
    google.protobuf.Timestamp last_request_at = 6;
}

// ========================================
// 模型管理
// ========================================

message ListModelsRequest {
    string organization_id = 1;
    ModelType type = 2;
    ModelStatus status = 3;
    int32 page = 4;
    int32 page_size = 5;
}

message ListModelsResponse {
    bool success = 1;
    repeated Model models = 2;
    int32 total = 3;
    string error = 4;
}

message GetModelRequest {
    string model_id = 1;
}

message GetModelResponse {
    bool success = 1;
    Model model = 2;
    string error = 3;
}

message DeployModelRequest {
    string model_id = 1;
    string organization_id = 2;
    ModelConfig config = 3;
    string backend = 4; // transformers, vllm, tensorrt
}

message DeployModelResponse {
    bool success = 1;
    string deployment_id = 2;
    ModelStatus status = 3;
    string error = 4;
}

message UndeployModelRequest {
    string model_id = 1;
    string organization_id = 2;
}

message UndeployModelResponse {
    bool success = 1;
    string message = 2;
    string error = 3;
}

message GetModelStatusRequest {
    string model_id = 1;
}

message GetModelStatusResponse {
    bool success = 1;
    ModelStatus status = 2;
    ModelMetrics metrics = 3;
    string error = 4;
}

// ========================================
// 推理服务
// ========================================

message GenerateTextRequest {
    string model_id = 1;
    string prompt = 2;
    int32 max_tokens = 3;
    double temperature = 4;
    double top_p = 5;
    repeated string stop_sequences = 6;
    google.protobuf.Struct parameters = 7;
}

message GenerateTextResponse {
    bool success = 1;
    string text = 2;
    int32 tokens_generated = 3;
    double processing_time_ms = 4;
    google.protobuf.Struct metadata = 5;
    string error = 6;
}

message ChatCompletionRequest {
    string model_id = 1;
    repeated ChatMessage messages = 2;
    int32 max_tokens = 3;
    double temperature = 4;
    bool stream = 5;
    google.protobuf.Struct parameters = 6;
}

message ChatMessage {
    string role = 1; // system, user, assistant
    string content = 2;
    google.protobuf.Struct metadata = 3;
}

message ChatCompletionResponse {
    bool success = 1;
    string content = 2;
    string finish_reason = 3;
    int32 prompt_tokens = 4;
    int32 completion_tokens = 5;
    int32 total_tokens = 6;
    double processing_time_ms = 7;
    string error = 8;
}

message GenerateEmbeddingRequest {
    string model_id = 1;
    repeated string texts = 2;
}

message GenerateEmbeddingResponse {
    bool success = 1;
    repeated Embedding embeddings = 2;
    int32 total_tokens = 3;
    double processing_time_ms = 4;
    string error = 5;
}

message Embedding {
    repeated float values = 1;
    int32 dimension = 2;
}

// ========================================
// 批量推理
// ========================================

message BatchInferenceRequest {
    string model_id = 1;
    repeated BatchItem items = 2;
    google.protobuf.Struct config = 3;
}

message BatchItem {
    string item_id = 1;
    string prompt = 2;
    google.protobuf.Struct parameters = 3;
}

message BatchInferenceResponse {
    bool success = 1;
    string batch_id = 2;
    int32 total_items = 3;
    BatchStatus status = 4;
    string error = 5;
}

message GetBatchStatusRequest {
    string batch_id = 1;
}

message GetBatchStatusResponse {
    bool success = 1;
    BatchStatus status = 2;
    int32 completed_items = 3;
    int32 total_items = 4;
    repeated BatchResult results = 5;
    string error = 6;
}

enum BatchStatus {
    BATCH_STATUS_UNKNOWN = 0;
    BATCH_STATUS_PENDING = 1;
    BATCH_STATUS_RUNNING = 2;
    BATCH_STATUS_COMPLETED = 3;
    BATCH_STATUS_FAILED = 4;
}

message BatchResult {
    string item_id = 1;
    bool success = 2;
    string result = 3;
    string error = 4;
}

// ========================================
// 健康状态
// ========================================

message GetModelHealthRequest {
    string model_id = 1;
}

message GetModelHealthResponse {
    bool success = 1;
    ModelHealth health = 2;
    string error = 3;
}

message ModelHealth {
    string model_id = 1;
    ModelStatus status = 2;
    double gpu_utilization = 3;
    double memory_utilization = 4;
    int32 active_requests = 5;
    int32 queue_length = 6;
    google.protobuf.Timestamp last_request = 7;
}

message GetServiceHealthRequest {
}

message GetServiceHealthResponse {
    bool success = 1;
    ServiceHealth health = 2;
    string error = 3;
}

message ServiceHealth {
    string service_name = 1;
    string version = 2;
    bool healthy = 3;
    int32 deployed_models = 4;
    double total_gpu_utilization = 5;
    double total_memory_utilization = 6;
    google.protobuf.Timestamp uptime = 7;
}